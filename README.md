# Volume Segmentation Tool with GUI

This repository holds the script for Volume Segmentation Tool and its Gradio-based Webui.

Paper is under review, coming soon...

Supporting Operating Systems includes: Windows and Linux.

(macOS is supported in theory, however some necessary PyTorch operations needed is not yet supported on MPS backend. Nothing I can do here)

## About the Tool

Volume Segmentation Tool is a python based tool that utilizes deep learning to perform volumetric electron microscopy image segmentations, both semantic and instance segmentation.

Based on [Pytorch](https://pytorch.org/) backend. Includes a [Gradio](https://www.gradio.app/) based graphical user interface. 

The desired images are  8bit or 16bit grey scale 3D tif/hdf as commonly generated by electron microscopes. The desired labels are either binary mask where 0 is background and 1 is foreground (semantic), or each value represent a different object (instance).

This tool does __not__ support 2D image segmentation, nor colorful image segmentation. In which case you should consider [ilastik](https://www.ilastik.org/) 
or [Trainable Weka Segmentation](https://imagej.net/plugins/tws/) or [nnUNet](https://github.com/MIC-DKFZ/nnUNet).

![How_much_can_it_help.png](GitHub_Res%2FHow_much_can_it_help.png)
## Advantages

- High efficiency
  - Custom implemented augmentations specialised in volumetric images
  - Process many depth slices all once, rather than slice by slice
  - Support fp16/bf16 training
  - Up to 20x speedup compare to nnUNet
- Versatile
  - Semantic Segmentation & Instance Segmentation
  - Isotropic & anisotropic images
  - Adaptive network type, size and depth
  - Support AMD GPU (only under Linux)
- Easy to use
  - One click installation script
  - Graphical User Interface
  - Visualisation tools for data augmentation and network activations
  - Visualise network output on the fly
  - TensorBoard Logging & Can export as Excel spreadsheet

## Limitations

- Does not support 2D images, nor images with colours (grey scale only)
- Since it's based on Deep Learning, the tool needs to be used with a discrete GPU
  - It's possible to run this tool without a discrete GPU, however it will run __extremely__ slowly
  - Recommended minimal GPU requirement: 4GB of Video Memory, made by Nvidia or AMD
- Since it's based on Deep Learning, the user has to create training samples to train the network before it could perform segmentation
  - For more information, please see [Tutorials](#tutorials).

## Installation

1. Install [Python 3.10](https://www.python.org/downloads/release/python-31010/). (Newer versions of Python should work as well)
   - During the installation process, ensure that you select the option to add Python to the 'PATH' environment variable.
2. Install [Git](https://git-scm.com/).
   - If you are using Linux, it's highly likely you can skip this step.
3. Open a terminal and navigate to the desired installation directory.
4. Clone the repository by running the following command:
   ```shell
   git clone https://github.com/fgdfgfthgr-fox/Volume_Seg_Tool.git
   ```
5. Run the corresponding "install_dependencies" script for your system.
   - For Windows, it would be install_dependencies_Windows.bat

6. Wait for the script to finish, which could take a while depends on your network speed.

## Starting GUI

1. Run the corresponding "start_WebUI" script for your system. This would open up a terminal.
   - For Windows, it would be start_WebUI_Windows.bat
2. Your web browser should automatically open up a "website" with url "127.0.0.1:7860" or something similar.

## Tutorials

Please see the [Wiki](https://github.com/fgdfgfthgr-fox/Volume_Seg_Tool/wiki).

## Evaluation
All number below were obtained with semantic segmentation
<!------>
  | Dataset                                                                                       | Time taken                                                                | Dice Score                                 | Peak VRAM Use |
  |-----------------------------------------------------------------------------------------------|---------------------------------------------------------------------------|--------------------------------------------|---------------|
  | [UroCell](https://github.com/MancaZerovnikMekuc/UroCell) Mitochondria validate on fib-1-0-0-0 | 1.0 hour                                                                  | 0.8926                                     | 7.5GB         |
More evaluation please see the upcoming paper...

![Paper Figure 5.png](GitHub_Res%2FFigure05.png)
A. Ground Truth. B. VST predicted result C. DeepImageJ D. ZeroCostDL4mic E. nnUNet
![Paper Figure 7.png](GitHub_Res%2FFigure07.png)
A. Ground Truth. B. VST predicted result

## Credits

This tool was developed under the scholarship funding from [AgResearch](https://www.agresearch.co.nz/),
and was helped by the members of the [Bostina Lab](https://search.otago.ac.nz/s/search.html?collection=uoot-prod%7Esp-otago-search&profile=_default&query=bostina+lab) of the [University of Otago](https://www.otago.ac.nz/).
As well as Lech Szymanski from the Computer Science department.

The example dataset included in this repository was collected by [Vincent Casser](https://casser.io/connectomics/).

The [UroCell](https://github.com/MancaZerovnikMekuc/UroCell) Dataset was heavily used during the development of the tool.

Special thanks to YunBo Wang from [Xidian University](https://www.xidian.edu.cn/), who gave me exceptional helps at the early stage of development.
